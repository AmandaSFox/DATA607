---
title: "Week_7_Fox"
author: "Amanda Fox"
date: 3/10/2024
format: html
---

### Introduction
  
The purpose of this week's assignment was to practice working with JSON, XML, and HTML data in R by manually creating three copies of a simple data table, one in each of these three languages, and then importing them into R dataframes. As this was my first experience with any of these languages, it was a challenging but beneficial exercise.

For my content, I chose three books on how dogs perceive the world. All three were written by canine cognition researchers at Barnard College and Duke University and are based on their years of research into the capabilities and psychology of dogs. In particular, I am fascinated by their descriptions of dogs' sense of smell and how that shapes their perception and cognition (disclaimer: we have several dogs at home including a young bloodhound mix with an otherworldly sense of smell). They are well-written and engaging casual reads, woven through with stories of dogs the authors have personally known and loved, which makes them some of my favorites.

For these three books, I referred to Amazon and pulled in nine variables, creating a small table in Excel as a model for my JSON, XML, and HTML code.

Then I began with the libraries:

```{r libraries}

library(tidyverse)
library(jsonlite)
library(RCurl)
library(XML)
library(xml2)
library(rvest)

```

### JSON

First I used Notepad++ to create a JSON file with my Excel table as a reference: https://raw.githubusercontent.com/AmandaSFox/DATA607/main/Week_7/Books.json

Then I brought it into R as follows. There were a number of packages available but the fromJSON function in the jsonlite package brought this particular table directly into a dataframe in a single step, whereas others required a few more steps and/or transformations.

I did notice that R brought in all data elements as character type, so depending on the desired analysis, one might need to convert some numeric or date fields before using.

```{r jsonfile}

path_json <- "https://raw.githubusercontent.com/AmandaSFox/DATA607/main/Week_7/Books.json"

#-------- Use function from jsonlite package to create dataframe directly from JSON file in one step

df_json <- jsonlite::fromJSON(path_json) 

str(df_json)

df_json

```
### XML

To create the same data table in XML, I used Notepad++ again: https://raw.githubusercontent.com/AmandaSFox/DATA607/main/Week_7/Books2.xml

XML was more complicated to bring into R as there was no simple one-step function like jsonlite provided above, and I tried a few XML packages and functions. After experimentation, I used functions from the RCurl and the XML packages.

First, I used getURL which created an "External Pointer" and xmlParse to bring in the data in a format that looked just like the original XML format (below). This two-step process seemed to be the key, and then I was able to use to some intuitive xml-specific functions like xmlToList and xmlToDataFrame to work with the data without any issue.

As happened with the JSON file, R brought in all data elements from my XML file as character type. 

```{r xmlfile}

path_xml <- "https://raw.githubusercontent.com/AmandaSFox/DATA607/main/Week_7/Books2.xml"

# -------- Get data with getURL and parse the XML code with xmlParse
data_xml <- getURL(path_xml) %>% 
  xmlParse()

# -------- Create dataframe from XML
df_xml<-xmlToDataFrame(data_xml) 

str(df_xml)

df_xml

```

### HTML

Finally, I created an HTML file using Notepad++ and my XML file for reference: 
https://raw.githubusercontent.com/AmandaSFox/DATA607/main/Week_7/Books2.html

Bringing it into R was conceptually similar to XML, and I used the rvest package in this case.

Unlike the XML or JSON import processes, the HTML import process coerced all fields with numeric values to int or num (but left dates as chr). In the case of Amazon ratings, this is appropriate; in the case of ISBN numbers, I would probably use double quotes in HTML or otherwise try to force R to consider it a character field so as not to lose any leading zeroes or cause issues with  joins to other tables. 

Also unlike the JSON- and XML-based dataframes, the HTML-based dataframe was the only one where the nulls were not populated with NA. 

```{r htmlfile}

path_html <- "https://raw.githubusercontent.com/AmandaSFox/DATA607/main/Week_7/Books2.html"

#-------- Similar to XML
data_html <- getURL(path_html) %>% 
  htmlParse()

#-------- From rvest package
df_html<-read_html(path_html)%>%
  html_node("table") %>%
  html_table()

str(df_html)
df_html

```

In the end, the JSON and XML dataframes were identical, while the HTML dataframe did not have NAs in the null data elements and the numeric fields were all forced to num or int by default.